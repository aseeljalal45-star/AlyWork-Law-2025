import pandas as pd
import os
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
from datetime import datetime
import json

class MiniLegalAI:
    def __init__(self, workbook_path=None):
        """
        ๐ค ุงููุณุงุนุฏ ุงููุงูููู ุงูุฐูู - ุงูุฅุตุฏุงุฑ ุงููุญุณู
        
        ูุนุชูุฏ ุนูู ุฎูุงุฑุฒููุงุช ML ููุจุญุซ ุงูุฐูู ูู ุงูุชุดุฑูุนุงุช ุงููุงููููุฉ
        """
        # ุฌูุจ ุงูุฅุนุฏุงุฏุงุช
        config = st.session_state.get("config", {})
        self.ai_enabled = config.get("AI", {}).get("ENABLE", True)
        self.min_similarity_threshold = config.get("AI", {}).get("MIN_SIMILARITY", 0.1)
        
        if not self.ai_enabled:
            st.warning("๐ค ุงููุณุงุนุฏ ุงูุฐูู ูุนุทู ูู ุฅุนุฏุงุฏุงุช ุงููุธุงู.")
        
        # ุงููุณุงุฑุงุช ูุงูุฅุนุฏุงุฏุงุช
        self.workbook_path = workbook_path or config.get("WORKBOOK_PATH", "")
        self.last_updated = None
        
        # ุชููุฆุฉ ููููุงุช ML
        self.vectorizer = None
        self.tfidf_matrix = None
        self.feature_names = None
        
        # ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุงูุชุฑุงุถูุฉ
        self.db = pd.DataFrame(columns=['ุงููุงุฏุฉ', 'ุงููุณู', 'ุงููุต', 'ูุซุงู', 'ุงูุชุตููู', 'ุงูุฃูููุฉ'])
        
        # ุฅุญุตุงุฆูุงุช ุงูุงุณุชุฎุฏุงู
        self.search_history = []
        self.total_searches = 0
        
        # ุงูุชุญููู ุงูุชููุงุฆู ุฅุฐุง ูุงู ุงูููู ููุฌูุฏุงู
        if self.workbook_path and os.path.exists(self.workbook_path):
            self.load_database_from_excel()
            if not self.db.empty:
                self.build_tfidf_matrix()

    # ==============================
    # ๐ ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช
    # ==============================
    def load_database_from_excel(self, path=None):
        """ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูู ููู Excel ูุน ูุนุงูุฌุฉ ูุชูุฏูุฉ ููุฃุฎุทุงุก"""
        path = path or self.workbook_path
        
        if not path or not os.path.exists(path):
            st.warning(f"โ๏ธ ููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุบูุฑ ููุฌูุฏ: {path}")
            self.db = pd.DataFrame(columns=['ุงููุงุฏุฉ', 'ุงููุณู', 'ุงููุต', 'ูุซุงู', 'ุงูุชุตููู', 'ุงูุฃูููุฉ'])
            return False
        
        try:
            # ูุฑุงุกุฉ ุงูููู ูุน ูุนุงูุฌุฉ ูุฎุชูู ุงูุตูุบ
            df = pd.read_excel(path, engine='openpyxl')
            
            # ุงูุชุฃูุฏ ูู ูุฌูุฏ ุงูุฃุนูุฏุฉ ุงูุฃุณุงุณูุฉ
            required_columns = ['ุงููุงุฏุฉ', 'ุงููุณู', 'ุงููุต', 'ูุซุงู']
            for col in required_columns:
                if col not in df.columns:
                    df[col] = ""
            
            # ุฅุถุงูุฉ ุฃุนูุฏุฉ ุฅุถุงููุฉ ุฅุฐุง ูู ุชูู ููุฌูุฏุฉ
            optional_columns = ['ุงูุชุตููู', 'ุงูุฃูููุฉ', 'ุชุงุฑูุฎ_ุงูุชุญุฏูุซ']
            for col in optional_columns:
                if col not in df.columns:
                    df[col] = ""
            
            # ุชูุธูู ุงูุจูุงูุงุช
            df = df[required_columns + optional_columns]
            df.fillna("", inplace=True)
            
            # ุฅุฒุงูุฉ ุงูุตููู ุงููุงุฑุบุฉ
            df = df[df['ุงููุต'].str.strip() != ""]
            
            self.db = df
            self.last_updated = datetime.now()
            
            # ุญูุธ ูู session state ูููุตูู ุงูุณุฑูุน
            st.session_state['ai_db'] = df
            st.session_state['db_loaded'] = True
            
            st.success(f"โ ุชู ุชุญููู {len(df)} ุณุฌู ูุงูููู ุจูุฌุงุญ")
            return True
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ูู ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช: {str(e)}")
            self.db = pd.DataFrame(columns=required_columns + optional_columns)
            return False

    # ==============================
    # ๐งน ุชูุธูู ุงููุตูุต ุงููุชูุฏู
    # ==============================
    @staticmethod
    def preprocess_text(text):
        """ุชูุธูู ูุชุญุถูุฑ ุงููุต ููุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ"""
        if pd.isna(text) or text == "":
            return ""
        
        text = str(text).strip()
        
        # ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ ูุน ุงูุญูุงุธ ุนูู ุงูุญุฑูู ุงูุนุฑุจูุฉ
        text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
        
        # ุชูููู ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ
        text = re.sub(r"\s+", " ", text)
        
        # ุชุญููู ุฅูู ุญุฑูู ุตุบูุฑุฉ (ูููููุงุช ุงูุฅูุฌููุฒูุฉ ููุท)
        text = text.lower()
        
        return text

    # ==============================
    # ๐๏ธ ุจูุงุก ูุตูููุฉ TF-IDF ุงููุญุณูุฉ
    # ==============================
    def build_tfidf_matrix(self):
        """ุจูุงุก ูุตูููุฉ TF-IDF ููุจุญุซ ุงูุฏูุงูู ุงููุชูุฏู"""
        if self.db.empty:
            st.warning("โ๏ธ ูุง ูููู ุจูุงุก ูุตูููุฉ ุงูุจุญุซ - ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุงุฑุบุฉ")
            return False
        
        try:
            # ุชุญุถูุฑ ุงููุตูุต
            corpus = self.db['ุงููุต'].apply(self.preprocess_text).tolist()
            
            # ุฅุนุฏุงุฏ ุงูู Vectorizer ูุน ุฅุนุฏุงุฏุงุช ูุชูุฏูุฉ ููุบุฉ ุงูุนุฑุจูุฉ
            self.vectorizer = TfidfVectorizer(
                max_features=1000,
                min_df=1,
                max_df=0.8,
                ngram_range=(1, 2),  # ุฏุนู ูููููุงุช ุงููุฑูุจุฉ
                stop_words=None  # ูููู ุฅุถุงูุฉ ูุงุฆูุฉ ุชููู ููุนุฑุจูุฉ ูุงุญูุงู
            )
            
            # ุจูุงุก ุงููุตูููุฉ
            self.tfidf_matrix = self.vectorizer.fit_transform(corpus)
            self.feature_names = self.vectorizer.get_feature_names_out()
            
            st.success(f"๐ฏ ุชู ุจูุงุก ูุตูููุฉ ุงูุจุญุซ ุจู {len(self.feature_names)} ููุฒุฉ ูุบููุฉ")
            return True
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ูู ุจูุงุก ูุตูููุฉ ุงูุจุญุซ: {str(e)}")
            return False

    # ==============================
    # ๐ ุงูุจุญุซ ุงูุฐูู ุงููุชูุฏู
    # ==============================
    def advanced_search(self, query, top_n=3, min_score=0.1):
        """
        ุจุญุซ ุฐูู ูุชูุฏู ูู ุงูุชุดุฑูุนุงุช ุงููุงููููุฉ
        
        Args:
            query (str): ุงุณุชุนูุงู ุงูุจุญุซ
            top_n (int): ุนุฏุฏ ุงููุชุงุฆุฌ ุงููุทููุจุฉ
            min_score (float): ุงูุญุฏ ุงูุฃุฏูู ูุฏูุฉ ุงููุทุงุจูุฉ
            
        Returns:
            list: ูุงุฆูุฉ ุจุงููุชุงุฆุฌ ูุน ุงูุชูุงุตูู
        """
        # ูุญุต ุงูุฅุนุฏุงุฏุงุช ุงูุฃุณุงุณูุฉ
        if not self.ai_enabled:
            return [{
                "text": "๐ค ุงููุณุงุนุฏ ุงูุฐูู ูุนุทู ุญุงูููุง",
                "reference": "",
                "example": "",
                "score": 0,
                "article": "",
                "section": ""
            }]
        
        if self.db.empty or self.tfidf_matrix is None:
            return [{
                "text": "โ๏ธ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุบูุฑ ุฌุงูุฒุฉ ููุจุญุซ",
                "reference": "",
                "example": "",
                "score": 0,
                "article": "",
                "section": ""
            }]
        
        # ุชุณุฌูู ุงูุจุญุซ ูู ุงูุณุฌู
        self.total_searches += 1
        self.search_history.append({
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "results_count": 0
        })
        
        try:
            # ุชุญุถูุฑ ุงูุงุณุชุนูุงู
            processed_query = self.preprocess_text(query)
            if not processed_query.strip():
                return [{
                    "text": "โ๏ธ ูุฑุฌู ุฅุฏุฎุงู ุงุณุชุจุญุซ ูุงุถุญ",
                    "reference": "",
                    "example": "",
                    "score": 0,
                    "article": "",
                    "section": ""
                }]
            
            # ุชุญููู ุงูุงุณุชุนูุงู ุฅูู ูุชุฌู
            query_vec = self.vectorizer.transform([processed_query])
            
            # ุญุณุงุจ ุงูุชุดุงุจู
            similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()
            
            # ุงูุญุตูู ุนูู ุฃูุถู ุงููุชุงุฆุฌ
            top_indices = similarities.argsort()[::-1][:top_n]
            
            results = []
            for idx in top_indices:
                score = similarities[idx]
                
                # ุชุตููุฉ ุงููุชุงุฆุฌ ุฐุงุช ุงูุฏูุฉ ุงูููุฎูุถุฉ
                if score < min_score:
                    continue
                
                row = self.db.iloc[idx]
                result = {
                    "text": row.get("ุงููุต", ""),
                    "reference": f"ุงููุงุฏุฉ {row.get('ุงููุงุฏุฉ', '')} - ุงููุณู: {row.get('ุงููุณู', '')}",
                    "example": row.get("ูุซุงู", ""),
                    "score": round(score * 100, 2),
                    "article": row.get("ุงููุงุฏุฉ", ""),
                    "section": row.get("ุงููุณู", ""),
                    "category": row.get("ุงูุชุตููู", ""),
                    "importance": row.get("ุงูุฃูููุฉ", "")
                }
                results.append(result)
            
            # ุชุญุฏูุซ ุณุฌู ุงูุจุญุซ
            if self.search_history:
                self.search_history[-1]["results_count"] = len(results)
            
            if not results:
                return [{
                    "text": "๐ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ ุชุทุงุจู ุงุณุชุนูุงูู",
                    "reference": "ุฌุฑุจ ุงุณุชุฎุฏุงู ูููุงุช ุจุญุซูุฉ ูุฎุชููุฉ",
                    "example": "",
                    "score": 0,
                    "article": "",
                    "section": ""
                }]
            
            return results
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ูู ุนูููุฉ ุงูุจุญุซ: {str(e)}")
            return [{
                "text": "โ๏ธ ุญุฏุซ ุฎุทุฃ ูู ุงูุจุญุซุ ูุฑุฌู ุงููุญุงููุฉ ูุงุญูุงู",
                "reference": "",
                "example": "",
                "score": 0,
                "article": "",
                "section": ""
            }]

    # ==============================
    # ๐ ุฅุญุตุงุฆูุงุช ูุฃุฏูุงุช ูุณุงุนุฏุฉ
    # ==============================
    def get_statistics(self):
        """ุฅุฑุฌุงุน ุฅุญุตุงุฆูุงุช ุงุณุชุฎุฏุงู ุงููุณุงุนุฏ"""
        return {
            "total_records": len(self.db),
            "total_searches": self.total_searches,
            "last_updated": self.last_updated,
            "ai_enabled": self.ai_enabled,
            "search_history": self.search_history[-10:]  # ุขุฎุฑ 10 ุนูููุงุช ุจุญุซ
        }
    
    def search_similar_articles(self, article_text, top_n=2):
        """ุงูุจุญุซ ุนู ููุงุฏ ูุดุงุจูุฉ ููุต ูุงุฏุฉ ูุนููุฉ"""
        return self.advanced_search(article_text, top_n=top_n)
    
    def get_categories_stats(self):
        """ุฅุญุตุงุฆูุงุช ุงูุชุตูููุงุช ุงูููุฌูุฏุฉ ูู ุงููุงุนุฏุฉ"""
        if self.db.empty or 'ุงูุชุตููู' not in self.db.columns:
            return {}
        
        return self.db['ุงูุชุตููู'].value_counts().to_dict()

    # ==============================
    # ๐ ุฅุนุงุฏุฉ ุงูุชุญููู ูุงูุชุญุฏูุซ
    # ==============================
    def reload(self, new_path=None):
        """ุฅุนุงุฏุฉ ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุชุญุฏูุซ ูุตูููุฉ ุงูุจุญุซ"""
        if new_path:
            self.workbook_path = new_path
        
        success = self.load_database_from_excel()
        if success and not self.db.empty:
            self.build_tfidf_matrix()
            st.success("๐ ุชู ุชุญุฏูุซ ูุงุนุฏุฉ ุงูุจูุงูุงุช ููุตูููุฉ ุงูุจุญุซ ุจูุฌุงุญ")
        else:
            st.warning("โ๏ธ ูู ูุชู ุชุญุฏูุซ ูุงุนุฏุฉ ุงูุจูุงูุงุช")
        
        return success

    # ==============================
    # ๐พ ุญูุธ ูุชุตุฏูุฑ ุงูุจูุงูุงุช
    # ==============================
    def export_search_history(self, format='json'):
        """ุชุตุฏูุฑ ุณุฌู ุงูุจุญุซ"""
        if format == 'json':
            return json.dumps(self.search_history, ensure_ascii=False, indent=2)
        else:
            return pd.DataFrame(self.search_history).to_csv(index=False)

# ุฏุงูุฉ ูุณุงุนุฏุฉ ููุงุณุชุฎุฏุงู ุงูุณุฑูุน
def create_legal_ai(workbook_path=None):
    """ุฅูุดุงุก ูุซูู ูุณุงุนุฏ ูุงูููู ุฐูู"""
    return MiniLegalAI(workbook_path)

# ูุซุงู ููุงุณุชุฎุฏุงู
if __name__ == "__main__":
    # ุงุฎุชุจุงุฑ ุงููุธุงุฆู
    ai = MiniLegalAI("data/legal_database.xlsx")
    results = ai.advanced_search("ููุงูุฃุฉ ููุงูุฉ ุงูุฎุฏูุฉ")
    print(results)